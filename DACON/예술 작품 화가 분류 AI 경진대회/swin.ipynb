{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JRD26gCIEt23"},"outputs":[],"source":["# drive mount\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"H2DGZO2PF58V"},"source":["## Import Library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KEFqBUr7Eu7c"},"outputs":[],"source":["!pip install ttach\n","!pip install timm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gulvessbEzjr"},"outputs":[],"source":["import random\n","import pandas as pd\n","import numpy as np\n","import os\n","import cv2\n","\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import timm\n","\n","from tqdm.auto import tqdm\n","from copy import deepcopy\n","\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","import ttach as tta\n","\n","import torchvision.models as models\n","\n","from sklearn.metrics import f1_score\n","\n","import warnings\n","warnings.filterwarnings(action='ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UbQMZGcfE0px"},"outputs":[],"source":["# device 할당\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w9pqHf5RE1nD"},"outputs":[],"source":["CFG = {\n","    'IMG_SIZE_H': 220,\n","    'IMG_SIZE_W': 275,\n","    'EPOCHS': 50,\n","    'LEARNING_RATE': 3e-4,\n","    'BATCH_SIZE': 64,\n","    'SEED': 41,\n","    'PATIENCE' : 3\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3eP6g_llE3IG"},"outputs":[],"source":["# RandomSeed\n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(CFG['SEED'])"]},{"cell_type":"markdown","metadata":{"id":"7JPiaJShF8dU"},"source":["## Data Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CTwMbLRUE4aY"},"outputs":[],"source":["train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Artist_classification/data/train.csv')\n","train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RGvIIvasE5IB"},"outputs":[],"source":["def img_path_change(img_path):\n","  return '/content/drive/MyDrive/Colab Notebooks/Artist_classification/data' + str(img_path)[1:]\n","\n","train['img_path'] = train['img_path'].apply(img_path_change)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I1SIRWQPE5-O"},"outputs":[],"source":["# Label Encoding : artist들을 범주형 데이터로 변환\n","# 화가 이름 50명\n","le = preprocessing.LabelEncoder()\n","train['artist'] = le.fit_transform(train['artist'].values)"]},{"cell_type":"markdown","metadata":{"id":"sCl9N-JvF-kn"},"source":["## Train / Validation Split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LvkGqZX2E7Hp"},"outputs":[],"source":["train_df, val_df, _, _ = train_test_split(train, train['artist'].values, test_size=0.2, random_state=CFG['SEED'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hj25KPsfE8HP"},"outputs":[],"source":["train_df = train_df.sort_values(by=['id'])\n","train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qJ5uiYdIE8va"},"outputs":[],"source":["val_df = val_df.sort_values(by=['id'])\n","val_df.head()"]},{"cell_type":"markdown","metadata":{"id":"nipwxryfGBkk"},"source":["## Data Load"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vbIFMdWdE-Ju"},"outputs":[],"source":["# inference=True면 test 데이터라는 뜻.\n","# 따라서 target에 해당하는 artist를 return할 수 없음.\n","def get_data(df, infer=False):\n","  if infer:\n","    return df['img_path'].values\n","    \n","  return df['img_path'].values, df['artist'].values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LY37sONZE-13"},"outputs":[],"source":["# 파일 경로, 레이블\n","train_img_paths, train_labels = get_data(train_df)\n","val_img_paths, val_labels = get_data(val_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"76aaLfIzE_hU"},"outputs":[],"source":["# 여기서 9등분하고 train_imgs_labels, val_imgs_labels 만들기\n","def split_image(paths,labels):\n","  img_list = []\n","  label_list = []\n","\n","  for path, label in tqdm(zip(paths, labels)):\n","    image = cv2.imread(path)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    height,width,c = image.shape\n","\n","    half_h = height//2\n","    half_w = width//2\n","    queter_h = half_h//2\n","    queter_w = half_w//2\n","\n","    pos_list = [\n","        [0,half_w, 0,half_h],\n","        [half_w,width, 0,half_h],\n","        [0,half_w, half_h,height],\n","        [half_w,width, half_h,height],\n","        [0,half_w, queter_h,height-queter_h],\n","        [half_w,width, queter_h,height-queter_h],\n","        [queter_w,width-queter_w, 0,half_h],\n","        [queter_w,width-queter_w, half_h,height],\n","        [queter_w,width-queter_w, queter_h,height-queter_h]\n","    ]\n","\n","    for poses in pos_list:\n","      img_list.append(image[poses[2]:poses[3],poses[0]:poses[1]])\n","      label_list.append(label)\n","\n","  return img_list,label_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hfYieRY9FAtZ"},"outputs":[],"source":["train_imgs, train_labels = split_image(train_img_paths, train_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gU6Uj0VmFB5u"},"outputs":[],"source":["val_imgs, val_labels = split_image(val_img_paths, val_labels)"]},{"cell_type":"markdown","metadata":{"id":"4UiMpqG5GEQz"},"source":["## CustomDataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fn2xLXouFCon"},"outputs":[],"source":["# torch.utils.data.Dataset이라는 class를 상속받는 자식 클래스\n","class CustomDataset(Dataset):\n","\n","  # 데이터셋을 처음 선언할 때, 자동으로 호출.\n","  # 몇 가지 인수들을 입력받도록 만들 수 있다.\n","  def __init__(self, imgs, labels, transforms=None):\n","    self.imgs = imgs\n","    self.labels = labels\n","    self.transforms = transforms\n","\n","  # 데이터셋에서 특정 1개의 샘플을 가져오기\n","  # index는 몇 번째 데이터를 가져올건지에 대한 변수.\n","  def __getitem__(self, index):\n","    image = self.imgs[index]\n","\n","    # 아래 dataset 선언을 보면 transform이 사용됨.\n","    if self.transforms is not None:\n","      image = self.transforms(image=image)['image']\n","\n","    if self.labels is not None:\n","      label = self.labels[index]\n","      return image, label\n","    else:\n","      return image\n","\n","  # 데이터셋의 길이 (총 샘플의 수)\n","  # 데이터셋을 선언하고 dataloader를 사용할 때 내부적으로 사용\n","  ## 데이터셋의 len을 알아야 데이터로더가 미니 배치를 사용할 수 있기 때문\n","  def __len__(self):\n","    return len(self.imgs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jO11j48NFEJF"},"outputs":[],"source":["class TestDataset(Dataset):\n","  def __init__(self, img_paths, labels, transforms=None):\n","    self.img_paths = img_paths\n","    self.labels = labels\n","    self.transforms = transforms\n","\n","  def __getitem__(self, index):\n","    img_path = self.img_paths[index]\n","\n","    image = cv2.imread(img_path)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    \n","    if self.transforms is not None:\n","      image = self.transforms(image=image)['image']\n","\n","    if self.labels is not None:\n","      label = self.labels[index]\n","      return image, label\n","    else:\n","      return image\n","\n","  def __len__(self):\n","    return len(self.img_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6aE4r-0eFFYP"},"outputs":[],"source":["# Albumentation Augmentation\n","train_transform = A.Compose([\n","                            A.Resize(CFG['IMG_SIZE_H'],CFG['IMG_SIZE_W']),\n","                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n","                            A.HorizontalFlip(p=0.5),\n","                            A.VerticalFlip(p=0.5),\n","                            ToTensorV2()\n","                            ])\n","\n","test_transform = A.Compose([\n","                            A.Resize(CFG['IMG_SIZE_H'],CFG['IMG_SIZE_W']),\n","                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n","                            ToTensorV2()\n","                            ])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fu7WZ8NeFGvO"},"outputs":[],"source":["# Data Loader\n","train_dataset = CustomDataset(train_imgs, train_labels, train_transform)\n","train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n","\n","val_dataset = CustomDataset(val_imgs, val_labels, test_transform)\n","val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"]},{"cell_type":"markdown","metadata":{"id":"CfCLCR0DGHDm"},"source":["## Model Define"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jue5_eICFHna"},"outputs":[],"source":["class Network_swin(nn.Module):\n","    def __init__(self, num_classes=len(le.classes_)):\n","        super(Network_swin, self).__init__()\n","        self.backbone = models.swin_t(weights='IMAGENET1K_V1')\n","        self.classifier = nn.Linear(1000, num_classes)\n","        \n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"IzsM5jnKGIlj"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b_mnX3xwFOpF"},"outputs":[],"source":["def train(model, optimizer, train_loader, test_loader, scheduler, device):\n","  # 모델을 device에 할당\n","  model.to(device)\n","\n","  # early stopping\n","  es_count = 0\n","\n","  # Loss 정의\n","  criterion = nn.CrossEntropyLoss().to(device)\n","\n","  # Scheduler에서 사용할 변수 선언\n","  best_score = 0\n","  best_model = None\n","\n","  for epoch in range(1, CFG['EPOCHS'] + 1):\n","    # model을 train 모드로 전환\n","    model.train()\n","\n","    # loss값을 넣을 리스트 생성\n","    train_loss = []\n","\n","    # Epoch 진행\n","    for img, label in tqdm(iter(train_loader)):\n","      img, label = img.float().to(device), label.to(device)\n","\n","      # 과거에 이용한 mini batch 내 이미지, 레이블을 바탕으로 계산된 Loss의 Gradient값이 optimizer에 할당되어 있는 것을 방지.\n","      optimizer.zero_grad()\n","\n","      # pred값 \n","      model_pred = model(img)\n","\n","      # 선언한 Loss에 pred값과 정답을 넣기 \n","      loss = criterion(model_pred, label)\n","\n","      # backpropagation\n","      loss.backward()\n","\n","      # optimizer\n","      optimizer.step()\n","\n","      # loss값 추가\n","      train_loss.append(loss.item())\n","\n","    # 최종 loss값 생성\n","    tr_loss = np.mean(train_loss)\n","\n","    val_loss, val_score = validation(model, criterion, test_loader, device)\n","\n","    print(f'Epoch [{epoch}], Train Loss : [{tr_loss:.5f}] Val Loss : [{val_loss:.5f}] Val F1 Score : [{val_score:.5f}]')\n","\n","    # Scheduler\n","    if scheduler is not None:\n","      scheduler.step()\n","\n","    es_count += 1\n","\n","    # val_score을 기준으로 best model 선정\n","    if best_score < val_score:\n","      best_model = model\n","      best_score = val_score\n","      es_count = 0\n","\n","      # checkpoint\n","      best_acc_model = deepcopy(model.state_dict())\n","      print(\"model save!!\")\n","      torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/Artist_classification/model/best_swin.pt')\n","      \n","    if es_count > CFG['PATIENCE']:\n","      print('Early Stopping')\n","      break\n","\n","  return best_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ygrPT7MoFQdh"},"outputs":[],"source":["# 이번 대회에서는 F1 score를 사용\n","def competition_metric(true, pred):\n","    return f1_score(true, pred, average=\"macro\")\n","\n","def validation(model, criterion, test_loader, device):\n","\n","  # 모델을 평가용으로 전환 (dropout 등의 규제가 들어가지 않게 조절)\n","  model.eval()\n","  \n","  model_preds = []\n","  true_labels = []\n","\n","  val_loss = []\n","\n","  # 평가 단계에서 Gradient를 통해 파라미터 값이 업데이트되는 현상을 방지\n","  with torch.no_grad():\n","    for img, label in tqdm(iter(test_loader)):\n","      img, label = img.float().to(device), label.to(device)\n","      model_pred = model(img)\n","      loss = criterion(model_pred, label)\n","      val_loss.append(loss.item())\n","\n","      model_preds += model_pred.argmax(1).detach().cpu().numpy().tolist()\n","      true_labels += label.detach().cpu().numpy().tolist()\n","\n","  val_f1 = competition_metric(true_labels, model_preds)\n","  return np.mean(val_loss), val_f1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jn6SiKMuFR5D"},"outputs":[],"source":["# Run1\n","\n","model_swin = Network_swin()\n","model_swin.eval()\n","optimizer = torch.optim.Adam(params = model_swin.parameters(), lr = CFG[\"LEARNING_RATE\"])\n","\n","# scheduler\n","lambda1 = lambda epoch: 0.65 ** epoch\n","scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n","\n","infer_model_swin = train(model_swin, optimizer, train_loader, val_loader, scheduler, device)"]},{"cell_type":"markdown","metadata":{"id":"IqIOrBiEGMLs"},"source":["## Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"too422YqFYK8"},"outputs":[],"source":["# 모델 로딩이 필요하면 쓰세요\n","#infer_model_swin = Network_swin()\n","#infer_model_swin.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/Artist_classification/model/swin.pt', map_location=device))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rN6f3iiqFeR1"},"outputs":[],"source":["# TTA (test time augmentation)\n","tta_transforms = tta.Compose(\n","    [\n","        tta.HorizontalFlip(),\n","        tta.VerticalFlip(), \n","    ]\n",")\n","\n","tta_model = tta.ClassificationTTAWrapper(infer_model_swin, tta_transforms)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QDL-kvZuFn1a"},"outputs":[],"source":["test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Artist_classification/data/test.csv')\n","test.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cvEecS9kFl1K"},"outputs":[],"source":["test['img_path'] = test['img_path'].apply(lambda x : '/content/drive/MyDrive/Colab Notebooks/Artist_classification/data' + x[1:] )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8u4jp1tjFp2G"},"outputs":[],"source":["# Test에는 artist 정보가 없으니 infer=True\n","test_img_paths = get_data(test, infer=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VzVIyFitFqr3"},"outputs":[],"source":["test_dataset = TestDataset(test_img_paths, None, test_transform)\n","test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HC7OIcJXFr_t"},"outputs":[],"source":["def inference(model, test_loader, device):\n","    model.to(device)\n","    model.eval()\n","    \n","    model_preds = []\n","    \n","    with torch.no_grad():\n","        for img,himg in tqdm(iter(test_loader)):\n","            img, himg = img.float().to(device), himg.float().to(device)\n","            \n","            model_pred = model(img,himg)\n","            model_preds += model_pred.detach().cpu().numpy().tolist()\n","    \n","    print('Done.')\n","    return model_preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NoV9c09kFtAw"},"outputs":[],"source":["# eff inference\n","preds_swin = inference(tta_model, test_loader, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v32y6Vb7Fv1y"},"outputs":[],"source":["np.save('/content/drive/MyDrive/Colab Notebooks/Artist_classification/pred/pred_swin', preds_swin) "]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNAwTSNeuRq7XmvAhIXXIgF","collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.9.13 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.13"},"vscode":{"interpreter":{"hash":"cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"}}},"nbformat":4,"nbformat_minor":0}
