{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6145e4f4",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee418dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import os.path as osp\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a3f22b",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e3bf840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1350, 14) (1350, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Exter Qual</th>\n",
       "      <th>Garage Cars</th>\n",
       "      <th>Garage Area</th>\n",
       "      <th>Kitchen Qual</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>Bsmt Qual</th>\n",
       "      <th>Full Bath</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Year Remod/Add</th>\n",
       "      <th>Garage Yr Blt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2392</td>\n",
       "      <td>Ex</td>\n",
       "      <td>3</td>\n",
       "      <td>968</td>\n",
       "      <td>Ex</td>\n",
       "      <td>2392</td>\n",
       "      <td>2392</td>\n",
       "      <td>Ex</td>\n",
       "      <td>2</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>386250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1352</td>\n",
       "      <td>Gd</td>\n",
       "      <td>2</td>\n",
       "      <td>466</td>\n",
       "      <td>Gd</td>\n",
       "      <td>1352</td>\n",
       "      <td>1352</td>\n",
       "      <td>Ex</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>2007</td>\n",
       "      <td>2006</td>\n",
       "      <td>194000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>900</td>\n",
       "      <td>TA</td>\n",
       "      <td>1</td>\n",
       "      <td>288</td>\n",
       "      <td>TA</td>\n",
       "      <td>864</td>\n",
       "      <td>900</td>\n",
       "      <td>TA</td>\n",
       "      <td>1</td>\n",
       "      <td>1967</td>\n",
       "      <td>1967</td>\n",
       "      <td>1967</td>\n",
       "      <td>123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1174</td>\n",
       "      <td>TA</td>\n",
       "      <td>2</td>\n",
       "      <td>576</td>\n",
       "      <td>Gd</td>\n",
       "      <td>680</td>\n",
       "      <td>680</td>\n",
       "      <td>TA</td>\n",
       "      <td>1</td>\n",
       "      <td>1900</td>\n",
       "      <td>2006</td>\n",
       "      <td>2000</td>\n",
       "      <td>135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1958</td>\n",
       "      <td>Gd</td>\n",
       "      <td>3</td>\n",
       "      <td>936</td>\n",
       "      <td>Gd</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>Gd</td>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Overall Qual  Gr Liv Area Exter Qual  Garage Cars  Garage Area  \\\n",
       "0            10         2392         Ex            3          968   \n",
       "1             7         1352         Gd            2          466   \n",
       "2             5          900         TA            1          288   \n",
       "3             5         1174         TA            2          576   \n",
       "4             7         1958         Gd            3          936   \n",
       "\n",
       "  Kitchen Qual  Total Bsmt SF  1st Flr SF Bsmt Qual  Full Bath  Year Built  \\\n",
       "0           Ex           2392        2392        Ex          2        2003   \n",
       "1           Gd           1352        1352        Ex          2        2006   \n",
       "2           TA            864         900        TA          1        1967   \n",
       "3           Gd            680         680        TA          1        1900   \n",
       "4           Gd           1026        1026        Gd          2        2005   \n",
       "\n",
       "   Year Remod/Add  Garage Yr Blt  target  \n",
       "0            2003           2003  386250  \n",
       "1            2007           2006  194000  \n",
       "2            1967           1967  123000  \n",
       "3            2006           2000  135000  \n",
       "4            2005           2005  250000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '../dataset/housing'\n",
    "\n",
    "train = pd.read_csv(osp.join(data_dir, 'train.csv'))\n",
    "test = pd.read_csv(osp.join(data_dir, 'test.csv'))\n",
    "\n",
    "train.drop('id', axis=1, inplace=True) # id 제거\n",
    "test.drop('id', axis=1, inplace=True) # id 제거\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b4980c",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b85cca56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제거 전 : (1350, 14)\n",
      "제거 후 : (1349, 14)\n"
     ]
    }
   ],
   "source": [
    "# 중복값 제거\n",
    "print(\"제거 전 :\", train.shape)\n",
    "train = train.drop_duplicates()\n",
    "print(\"제거 후 :\", train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a0c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[train['Garage Yr Blt']> 2050] # 254\n",
    "train.loc[254, 'Garage Yr Blt'] = 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e22cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Exter Qual</th>\n",
       "      <th>Garage Cars</th>\n",
       "      <th>Garage Area</th>\n",
       "      <th>Kitchen Qual</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>Bsmt Qual</th>\n",
       "      <th>Full Bath</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Year Remod/Add</th>\n",
       "      <th>Garage Yr Blt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2392</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>968</td>\n",
       "      <td>5</td>\n",
       "      <td>2392</td>\n",
       "      <td>2392</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>386250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1352</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>466</td>\n",
       "      <td>4</td>\n",
       "      <td>1352</td>\n",
       "      <td>1352</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>2007</td>\n",
       "      <td>2006</td>\n",
       "      <td>194000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>288</td>\n",
       "      <td>3</td>\n",
       "      <td>864</td>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1967</td>\n",
       "      <td>1967</td>\n",
       "      <td>1967</td>\n",
       "      <td>123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1174</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>576</td>\n",
       "      <td>4</td>\n",
       "      <td>680</td>\n",
       "      <td>680</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1900</td>\n",
       "      <td>2006</td>\n",
       "      <td>2000</td>\n",
       "      <td>135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1958</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>936</td>\n",
       "      <td>4</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Overall Qual  Gr Liv Area  Exter Qual  Garage Cars  Garage Area  \\\n",
       "0            10         2392           5            3          968   \n",
       "1             7         1352           4            2          466   \n",
       "2             5          900           3            1          288   \n",
       "3             5         1174           3            2          576   \n",
       "4             7         1958           4            3          936   \n",
       "\n",
       "   Kitchen Qual  Total Bsmt SF  1st Flr SF  Bsmt Qual  Full Bath  Year Built  \\\n",
       "0             5           2392        2392          5          2        2003   \n",
       "1             4           1352        1352          5          2        2006   \n",
       "2             3            864         900          3          1        1967   \n",
       "3             4            680         680          3          1        1900   \n",
       "4             4           1026        1026          4          2        2005   \n",
       "\n",
       "   Year Remod/Add  Garage Yr Blt  target  \n",
       "0            2003           2003  386250  \n",
       "1            2007           2006  194000  \n",
       "2            1967           1967  123000  \n",
       "3            2006           2000  135000  \n",
       "4            2005           2005  250000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 품질 관련 변수 → 숫자로 매핑\n",
    "qual_cols = train.dtypes[train.dtypes == np.object].index\n",
    "def label_encoder(df_, qual_cols):\n",
    "    df = df_.copy()\n",
    "    mapping={\n",
    "        'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1\n",
    "    }\n",
    "    for col in qual_cols :\n",
    "        df[col] = df[col].map(mapping)\n",
    "    return df\n",
    "\n",
    "train = label_encoder(train, qual_cols)\n",
    "test = label_encoder(test, qual_cols)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09355c31",
   "metadata": {},
   "source": [
    "### 로그 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49003eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로그 변환 전 타겟 왜도 = 1.7205733874129123 / 로그 변환 후 타겟 왜도 = 0.08224141935772546\n"
     ]
    }
   ],
   "source": [
    "print(f'로그 변환 전 타겟 왜도 = {train.target.skew()} / 로그 변환 후 타겟 왜도 = {np.log1p(train.target).skew()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f974ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('target', axis = 1)\n",
    "y = np.log1p(train.target)\n",
    "\n",
    "target = test[X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9551603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.fillna(target.mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1d41a",
   "metadata": {},
   "source": [
    "## 파생 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3700a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_eng(data_):\n",
    "    data = data_.copy()\n",
    "    data['Year Gap Remod'] = data['Year Remod/Add'] - data['Year Built']\n",
    "    data['Car Area'] = data['Garage Area']/data['Garage Cars']\n",
    "    data['2nd flr SF'] = data['Gr Liv Area'] - data['1st Flr SF']\n",
    "    data['2nd flr'] = data['2nd flr SF'].apply(lambda x : 1 if x > 0 else 0)\n",
    "    data['Total SF'] = data[['Gr Liv Area',\"Garage Area\", \"Total Bsmt SF\"]].sum(axis=1)\n",
    "    data['Sum Qual'] = data[[\"Exter Qual\", \"Kitchen Qual\", \"Overall Qual\"]].sum(axis=1)\n",
    "    data['Garage InOut'] = data.apply(lambda x : 1 if x['Gr Liv Area'] != x['1st Flr SF'] else 0, axis=1)\n",
    "    return data\n",
    "\n",
    "train = feature_eng(train)\n",
    "test = feature_eng(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77894648",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e66edba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from ngboost import NGBRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "933b40df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 기준 정의\n",
    "def NMAE(true, pred):\n",
    "    mae = np.mean(np.abs(true-pred))\n",
    "    score = mae / np.mean(np.abs(true))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5245883",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmae_score = make_scorer(NMAE, greater_is_better=False)\n",
    "kf = KFold(n_splits = 10, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf71c3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLD Training.....\n",
      "1 FOLD NMAE = 0.08516773299438772\n",
      "\n",
      "2 FOLD Training.....\n",
      "2 FOLD NMAE = 0.1037334379169279\n",
      "\n",
      "3 FOLD Training.....\n",
      "3 FOLD NMAE = 0.09347602011178413\n",
      "\n",
      "4 FOLD Training.....\n",
      "4 FOLD NMAE = 0.11801350027022185\n",
      "\n",
      "5 FOLD Training.....\n",
      "5 FOLD NMAE = 0.08115283407751611\n",
      "\n",
      "6 FOLD Training.....\n",
      "6 FOLD NMAE = 0.10994532937271366\n",
      "\n",
      "7 FOLD Training.....\n",
      "7 FOLD NMAE = 0.09618690647772615\n",
      "\n",
      "8 FOLD Training.....\n",
      "8 FOLD NMAE = 0.08980927039476311\n",
      "\n",
      "9 FOLD Training.....\n",
      "9 FOLD NMAE = 0.09992001517045702\n",
      "\n",
      "10 FOLD Training.....\n",
      "10 FOLD NMAE = 0.0996037250804027\n",
      "\n",
      "10FOLD Mean of NMAE = 0.09770087718669004 & std = 0.010586797791535223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "\n",
    "# LinearRegression\n",
    "lr_pred = np.zeros(target.shape[0])\n",
    "lr_val = []\n",
    "for n, (tr_idx, val_idx) in enumerate(kf.split(X, y)) :\n",
    "    print(f'{n + 1} FOLD Training.....')\n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], np.expm1(y.iloc[val_idx])\n",
    "    \n",
    "    lr = LinearRegression(normalize=True)\n",
    "    lr.fit(tr_x, tr_y)\n",
    "    \n",
    "    val_pred = np.expm1(lr.predict(val_x))\n",
    "    val_nmae = NMAE(val_y, val_pred)\n",
    "    lr_val.append(val_nmae)\n",
    "    print(f'{n + 1} FOLD NMAE = {val_nmae}\\n')\n",
    "    \n",
    "    target_data = Pool(data = target, label = None)\n",
    "    fold_pred = lr.predict(target) / 10\n",
    "    lr_pred += fold_pred\n",
    "print(f'10FOLD Mean of NMAE = {np.mean(lr_val)} & std = {np.std(lr_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0e228ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLD Training.....\n",
      "1 FOLD NMAE = 0.08518848373299504\n",
      "\n",
      "2 FOLD Training.....\n",
      "2 FOLD NMAE = 0.10373385528863602\n",
      "\n",
      "3 FOLD Training.....\n",
      "3 FOLD NMAE = 0.09347833918874456\n",
      "\n",
      "4 FOLD Training.....\n",
      "4 FOLD NMAE = 0.11804341045588934\n",
      "\n",
      "5 FOLD Training.....\n",
      "5 FOLD NMAE = 0.0811462844719415\n",
      "\n",
      "6 FOLD Training.....\n",
      "6 FOLD NMAE = 0.10990169890105458\n",
      "\n",
      "7 FOLD Training.....\n",
      "7 FOLD NMAE = 0.09615468462531229\n",
      "\n",
      "8 FOLD Training.....\n",
      "8 FOLD NMAE = 0.08979721936963668\n",
      "\n",
      "9 FOLD Training.....\n",
      "9 FOLD NMAE = 0.09990731441863476\n",
      "\n",
      "10 FOLD Training.....\n",
      "10 FOLD NMAE = 0.09960676563692862\n",
      "\n",
      "10FOLD Mean of NMAE = 0.09769580560897734 & std = 0.010587156980456586\n"
     ]
    }
   ],
   "source": [
    "# Ridge\n",
    "rg_pred = np.zeros(target.shape[0])\n",
    "rg_val = []\n",
    "for n, (tr_idx, val_idx) in enumerate(kf.split(X, y)) :\n",
    "    print(f'{n + 1} FOLD Training.....')\n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], np.expm1(y.iloc[val_idx])\n",
    "    \n",
    "    rg = Ridge()\n",
    "    rg.fit(tr_x, tr_y)\n",
    "    \n",
    "    val_pred = np.expm1(rg.predict(val_x))\n",
    "    val_nmae = NMAE(val_y, val_pred)\n",
    "    rg_val.append(val_nmae)\n",
    "    print(f'{n + 1} FOLD NMAE = {val_nmae}\\n')\n",
    "    \n",
    "    target_data = Pool(data = target, label = None)\n",
    "    fold_pred = rg.predict(target) / 10\n",
    "    rg_pred += fold_pred\n",
    "print(f'10FOLD Mean of NMAE = {np.mean(rg_val)} & std = {np.std(rg_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1aa9e5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLD Training.....\n",
      "1 FOLD NMAE = 0.11014363861789106\n",
      "\n",
      "2 FOLD Training.....\n",
      "2 FOLD NMAE = 0.12859231598969093\n",
      "\n",
      "3 FOLD Training.....\n",
      "3 FOLD NMAE = 0.11696568675758723\n",
      "\n",
      "4 FOLD Training.....\n",
      "4 FOLD NMAE = 0.14546443450456834\n",
      "\n",
      "5 FOLD Training.....\n",
      "5 FOLD NMAE = 0.117609881931101\n",
      "\n",
      "6 FOLD Training.....\n",
      "6 FOLD NMAE = 0.11848164201239463\n",
      "\n",
      "7 FOLD Training.....\n",
      "7 FOLD NMAE = 0.1176699980965536\n",
      "\n",
      "8 FOLD Training.....\n",
      "8 FOLD NMAE = 0.09794562799080352\n",
      "\n",
      "9 FOLD Training.....\n",
      "9 FOLD NMAE = 0.11839055793197424\n",
      "\n",
      "10 FOLD Training.....\n",
      "10 FOLD NMAE = 0.13895906935473457\n",
      "\n",
      "10FOLD Mean of NMAE = 0.1210222853187299 & std = 0.01296166843443742\n"
     ]
    }
   ],
   "source": [
    "# Lasso\n",
    "ls_pred = np.zeros(target.shape[0])\n",
    "ls_val = []\n",
    "for n, (tr_idx, val_idx) in enumerate(kf.split(X, y)) :\n",
    "    print(f'{n + 1} FOLD Training.....')\n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], np.expm1(y.iloc[val_idx])\n",
    "    \n",
    "    ls = Lasso()\n",
    "    ls.fit(tr_x, tr_y)\n",
    "    \n",
    "    val_pred = np.expm1(ls.predict(val_x))\n",
    "    val_nmae = NMAE(val_y, val_pred)\n",
    "    ls_val.append(val_nmae)\n",
    "    print(f'{n + 1} FOLD NMAE = {val_nmae}\\n')\n",
    "    \n",
    "    target_data = Pool(data = target, label = None)\n",
    "    fold_pred = ls.predict(target) / 10\n",
    "    ls_pred += fold_pred\n",
    "print(f'10FOLD Mean of NMAE = {np.mean(ls_val)} & std = {np.std(ls_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d6fb136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLD Training.....\n",
      "1 FOLD NMAE = 0.10461174332147474\n",
      "\n",
      "2 FOLD Training.....\n",
      "2 FOLD NMAE = 0.12496946106957815\n",
      "\n",
      "3 FOLD Training.....\n",
      "3 FOLD NMAE = 0.11391873661792358\n",
      "\n",
      "4 FOLD Training.....\n",
      "4 FOLD NMAE = 0.14396580852288096\n",
      "\n",
      "5 FOLD Training.....\n",
      "5 FOLD NMAE = 0.10916888331837661\n",
      "\n",
      "6 FOLD Training.....\n",
      "6 FOLD NMAE = 0.11474280678068112\n",
      "\n",
      "7 FOLD Training.....\n",
      "7 FOLD NMAE = 0.10890616344143171\n",
      "\n",
      "8 FOLD Training.....\n",
      "8 FOLD NMAE = 0.09590813203234295\n",
      "\n",
      "9 FOLD Training.....\n",
      "9 FOLD NMAE = 0.1168680190598666\n",
      "\n",
      "10 FOLD Training.....\n",
      "10 FOLD NMAE = 0.1311141226888767\n",
      "\n",
      "10FOLD Mean of NMAE = 0.11641738768534331 & std = 0.013138721886320266\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet\n",
    "el_pred = np.zeros(target.shape[0])\n",
    "el_val = []\n",
    "for n, (tr_idx, val_idx) in enumerate(kf.split(X, y)) :\n",
    "    print(f'{n + 1} FOLD Training.....')\n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], np.expm1(y.iloc[val_idx])\n",
    "    \n",
    "    el = ElasticNet()\n",
    "    el.fit(tr_x, tr_y)\n",
    "    \n",
    "    val_pred = np.expm1(el.predict(val_x))\n",
    "    val_nmae = NMAE(val_y, val_pred)\n",
    "    el_val.append(val_nmae)\n",
    "    print(f'{n + 1} FOLD NMAE = {val_nmae}\\n')\n",
    "    \n",
    "    target_data = Pool(data = target, label = None)\n",
    "    fold_pred = el.predict(target) / 10\n",
    "    el_pred += fold_pred\n",
    "print(f'10FOLD Mean of NMAE = {np.mean(el_val)} & std = {np.std(el_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c6e8097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLD Training.....\n",
      "1 FOLD NMAE = 0.08973474875044812\n",
      "\n",
      "2 FOLD Training.....\n",
      "2 FOLD NMAE = 0.09342373840136703\n",
      "\n",
      "3 FOLD Training.....\n",
      "3 FOLD NMAE = 0.09635404984993284\n",
      "\n",
      "4 FOLD Training.....\n",
      "4 FOLD NMAE = 0.12391731285331489\n",
      "\n",
      "5 FOLD Training.....\n",
      "5 FOLD NMAE = 0.0954282024344578\n",
      "\n",
      "6 FOLD Training.....\n",
      "6 FOLD NMAE = 0.10285604236696992\n",
      "\n",
      "7 FOLD Training.....\n",
      "7 FOLD NMAE = 0.09251126055360143\n",
      "\n",
      "8 FOLD Training.....\n",
      "8 FOLD NMAE = 0.09576184784091606\n",
      "\n",
      "9 FOLD Training.....\n",
      "9 FOLD NMAE = 0.1035561882746765\n",
      "\n",
      "10 FOLD Training.....\n",
      "10 FOLD NMAE = 0.10218753408873578\n",
      "\n",
      "10FOLD Mean of NMAE = 0.09957309254144205 & std = 0.009233981537260185\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingRegressor\n",
    "gbr_pred = np.zeros(target.shape[0])\n",
    "gbr_val = []\n",
    "for n, (tr_idx, val_idx) in enumerate(kf.split(X, y)) :\n",
    "    print(f'{n + 1} FOLD Training.....')\n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], np.expm1(y.iloc[val_idx])\n",
    "    \n",
    "    gbr = GradientBoostingRegressor(random_state = 42, max_depth = 4, learning_rate = 0.05, n_estimators = 1000)\n",
    "    gbr.fit(tr_x, tr_y)\n",
    "    \n",
    "    val_pred = np.expm1(gbr.predict(val_x))\n",
    "    val_nmae = NMAE(val_y, val_pred)\n",
    "    gbr_val.append(val_nmae)\n",
    "    print(f'{n + 1} FOLD NMAE = {val_nmae}\\n')\n",
    "    \n",
    "    fold_pred = gbr.predict(target) / 10\n",
    "    gbr_pred += fold_pred\n",
    "print(f'10FOLD Mean of NMAE = {np.mean(gbr_val)} & std = {np.std(gbr_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0821673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLD Training.....\n",
      "1 FOLD NMAE = 0.0922156220711973\n",
      "\n",
      "2 FOLD Training.....\n",
      "2 FOLD NMAE = 0.10043356835559464\n",
      "\n",
      "3 FOLD Training.....\n",
      "3 FOLD NMAE = 0.10055273007851406\n",
      "\n",
      "4 FOLD Training.....\n",
      "4 FOLD NMAE = 0.12538377681850285\n",
      "\n",
      "5 FOLD Training.....\n",
      "5 FOLD NMAE = 0.09026369730237521\n",
      "\n",
      "6 FOLD Training.....\n",
      "6 FOLD NMAE = 0.09540843393029043\n",
      "\n",
      "7 FOLD Training.....\n",
      "7 FOLD NMAE = 0.08821015637488719\n",
      "\n",
      "8 FOLD Training.....\n",
      "8 FOLD NMAE = 0.09083184806061635\n",
      "\n",
      "9 FOLD Training.....\n",
      "9 FOLD NMAE = 0.10166828818352941\n",
      "\n",
      "10 FOLD Training.....\n",
      "10 FOLD NMAE = 0.10294099136490703\n",
      "\n",
      "10FOLD Mean of NMAE = 0.09879091125404145 & std = 0.010203790026087891\n"
     ]
    }
   ],
   "source": [
    "# RandomForestRegressor\n",
    "rf_pred = np.zeros(target.shape[0])\n",
    "rf_val = []\n",
    "for n, (tr_idx, val_idx) in enumerate(kf.split(X, y)) :\n",
    "    print(f'{n + 1} FOLD Training.....')\n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], np.expm1(y.iloc[val_idx])\n",
    "    \n",
    "    rf = RandomForestRegressor(random_state = 42, criterion = 'mae')\n",
    "    rf.fit(tr_x, tr_y)\n",
    "    \n",
    "    val_pred = np.expm1(rf.predict(val_x))\n",
    "    val_nmae = NMAE(val_y, val_pred)\n",
    "    rf_val.append(val_nmae)\n",
    "    print(f'{n + 1} FOLD NMAE = {val_nmae}\\n')\n",
    "    \n",
    "    fold_pred = rf.predict(target) / 10\n",
    "    rf_pred += fold_pred\n",
    "print(f'10FOLD Mean of NMAE = {np.mean(rf_val)} & std = {np.std(rf_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ef5e434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLD Training.....\n",
      "1 FOLD NMAE = 0.08540200060927182\n",
      "\n",
      "2 FOLD Training.....\n",
      "2 FOLD NMAE = 0.09392208071849062\n",
      "\n",
      "3 FOLD Training.....\n",
      "3 FOLD NMAE = 0.09342973709603332\n",
      "\n",
      "4 FOLD Training.....\n",
      "4 FOLD NMAE = 0.1158158053273631\n",
      "\n",
      "5 FOLD Training.....\n",
      "5 FOLD NMAE = 0.08613295738895065\n",
      "\n",
      "6 FOLD Training.....\n",
      "6 FOLD NMAE = 0.09519635820490327\n",
      "\n",
      "7 FOLD Training.....\n",
      "7 FOLD NMAE = 0.09119477028522797\n",
      "\n",
      "8 FOLD Training.....\n",
      "8 FOLD NMAE = 0.09006259727788231\n",
      "\n",
      "9 FOLD Training.....\n",
      "9 FOLD NMAE = 0.09642556796539417\n",
      "\n",
      "10 FOLD Training.....\n",
      "10 FOLD NMAE = 0.10160829361550165\n",
      "\n",
      "10FOLD Mean of NMAE = 0.09491901684890189 & std = 0.008319879236830889\n"
     ]
    }
   ],
   "source": [
    "# NGBRegressor\n",
    "ngb_pred = np.zeros(target.shape[0])\n",
    "ngb_val = []\n",
    "for n, (tr_idx, val_idx) in enumerate(kf.split(X, y)) :\n",
    "    print(f'{n + 1} FOLD Training.....')\n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], np.expm1(y.iloc[val_idx])\n",
    "    \n",
    "    ngb = NGBRegressor(random_state = 42, n_estimators = 1000, verbose = 0, learning_rate = 0.03)\n",
    "    ngb.fit(tr_x, tr_y, val_x, val_y, early_stopping_rounds = 300)\n",
    "    \n",
    "    val_pred = np.expm1(ngb.predict(val_x))\n",
    "    val_nmae = NMAE(val_y, val_pred)\n",
    "    ngb_val.append(val_nmae)\n",
    "    print(f'{n + 1} FOLD NMAE = {val_nmae}\\n')\n",
    "    \n",
    "    target_data = Pool(data = target, label = None)\n",
    "    fold_pred = ngb.predict(target) / 10\n",
    "    ngb_pred += fold_pred\n",
    "print(f'10FOLD Mean of NMAE = {np.mean(ngb_val)} & std = {np.std(ngb_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45b4bef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLD Training.....\n",
      "0:\tlearn: 0.2930177\ttest: 187886.6144612\tbest: 187886.6144612 (0)\ttotal: 139ms\tremaining: 6m 57s\n",
      "Stopped by overfitting detector  (750 iterations wait)\n",
      "\n",
      "bestTest = 187886.5491\n",
      "bestIteration = 142\n",
      "\n",
      "Shrink model to first 143 iterations.\n",
      "1 FOLD NMAE = 0.09278793165778815\n",
      "\n",
      "2 FOLD Training.....\n",
      "0:\tlearn: 0.2952100\ttest: 183672.7368567\tbest: 183672.7368567 (0)\ttotal: 1.9ms\tremaining: 5.69s\n",
      "Stopped by overfitting detector  (750 iterations wait)\n",
      "\n",
      "bestTest = 183672.7231\n",
      "bestIteration = 91\n",
      "\n",
      "Shrink model to first 92 iterations.\n",
      "2 FOLD NMAE = 0.119763220923516\n",
      "\n",
      "3 FOLD Training.....\n",
      "0:\tlearn: 0.2873214\ttest: 190826.8660616\tbest: 190826.8660616 (0)\ttotal: 1.88ms\tremaining: 5.63s\n",
      "Stopped by overfitting detector  (750 iterations wait)\n",
      "\n",
      "bestTest = 190826.8025\n",
      "bestIteration = 156\n",
      "\n",
      "Shrink model to first 157 iterations.\n",
      "3 FOLD NMAE = 0.10428467631314435\n",
      "\n",
      "4 FOLD Training.....\n",
      "0:\tlearn: 0.2923176\ttest: 176271.9526156\tbest: 176271.9526156 (0)\ttotal: 1.84ms\tremaining: 5.53s\n",
      "Stopped by overfitting detector  (750 iterations wait)\n",
      "\n",
      "bestTest = 176271.9525\n",
      "bestIteration = 44\n",
      "\n",
      "Shrink model to first 45 iterations.\n",
      "4 FOLD NMAE = 0.15771074368270357\n",
      "\n",
      "5 FOLD Training.....\n",
      "0:\tlearn: 0.2901793\ttest: 190352.2588231\tbest: 190352.2588231 (0)\ttotal: 1.85ms\tremaining: 5.55s\n",
      "1000:\tlearn: 0.0680866\ttest: 190352.1833605\tbest: 190352.1824251 (308)\ttotal: 754ms\tremaining: 1.5s\n",
      "Stopped by overfitting detector  (750 iterations wait)\n",
      "\n",
      "bestTest = 190352.1824\n",
      "bestIteration = 308\n",
      "\n",
      "Shrink model to first 309 iterations.\n",
      "5 FOLD NMAE = 0.09216172191770602\n",
      "\n",
      "6 FOLD Training.....\n",
      "0:\tlearn: 0.2890262\ttest: 197893.4583336\tbest: 197893.4583336 (0)\ttotal: 2.16ms\tremaining: 6.47s\n",
      "Stopped by overfitting detector  (750 iterations wait)\n",
      "\n",
      "bestTest = 197893.3619\n",
      "bestIteration = 152\n",
      "\n",
      "Shrink model to first 153 iterations.\n",
      "6 FOLD NMAE = 0.0896889774427096\n",
      "\n",
      "7 FOLD Training.....\n",
      "0:\tlearn: 0.2957983\ttest: 183106.7319688\tbest: 183106.7319688 (0)\ttotal: 2.21ms\tremaining: 6.62s\n",
      "1000:\tlearn: 0.0678052\ttest: 183106.6751391\tbest: 183106.6747063 (818)\ttotal: 817ms\tremaining: 1.63s\n",
      "Stopped by overfitting detector  (750 iterations wait)\n",
      "\n",
      "bestTest = 183106.6747\n",
      "bestIteration = 818\n",
      "\n",
      "Shrink model to first 819 iterations.\n",
      "7 FOLD NMAE = 0.0898607417019733\n",
      "\n",
      "8 FOLD Training.....\n",
      "0:\tlearn: 0.2969892\ttest: 176932.3561037\tbest: 176932.3561037 (0)\ttotal: 1.95ms\tremaining: 5.83s\n",
      "Stopped by overfitting detector  (750 iterations wait)\n",
      "\n",
      "bestTest = 176932.3305\n",
      "bestIteration = 59\n",
      "\n",
      "Shrink model to first 60 iterations.\n",
      "8 FOLD NMAE = 0.10568894901179725\n",
      "\n",
      "9 FOLD Training.....\n",
      "0:\tlearn: 0.2927212\ttest: 177433.8408407\tbest: 177433.8408407 (0)\ttotal: 1.94ms\tremaining: 5.81s\n",
      "Stopped by overfitting detector  (750 iterations wait)\n",
      "\n",
      "bestTest = 177433.8256\n",
      "bestIteration = 83\n",
      "\n",
      "Shrink model to first 84 iterations.\n",
      "9 FOLD NMAE = 0.11947647756866552\n",
      "\n",
      "10 FOLD Training.....\n",
      "0:\tlearn: 0.2876236\ttest: 199044.3203820\tbest: 199044.3203820 (0)\ttotal: 1.91ms\tremaining: 5.73s\n",
      "1000:\tlearn: 0.0679112\ttest: 199044.2250045\tbest: 199044.2243809 (708)\ttotal: 797ms\tremaining: 1.59s\n",
      "Stopped by overfitting detector  (750 iterations wait)\n",
      "\n",
      "bestTest = 199044.2244\n",
      "bestIteration = 708\n",
      "\n",
      "Shrink model to first 709 iterations.\n",
      "10 FOLD NMAE = 0.1096628524934866\n",
      "\n",
      "10FOLD Mean of NMAE = 0.10810862927134904 & std = 0.019772751244884073\n"
     ]
    }
   ],
   "source": [
    "# Catboost\n",
    "cb_pred = np.zeros(target.shape[0])\n",
    "cb_val = []\n",
    "for n, (tr_idx, val_idx) in enumerate(kf.split(X, y)) :\n",
    "    print(f'{n + 1} FOLD Training.....')\n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], np.expm1(y.iloc[val_idx])\n",
    "    \n",
    "    tr_data = Pool(data = tr_x, label = tr_y)\n",
    "    val_data = Pool(data = val_x, label = val_y)\n",
    "    \n",
    "    cb = CatBoostRegressor(depth = 4, random_state = 42, loss_function = 'MAE', n_estimators = 3000, learning_rate = 0.03, verbose = 0)\n",
    "    cb.fit(tr_data, eval_set = val_data, early_stopping_rounds = 750, verbose = 1000)\n",
    "    \n",
    "    val_pred = np.expm1(cb.predict(val_x))\n",
    "    val_nmae = NMAE(val_y, val_pred)\n",
    "    cb_val.append(val_nmae)\n",
    "    print(f'{n + 1} FOLD NMAE = {val_nmae}\\n')\n",
    "    \n",
    "    target_data = Pool(data = target, label = None)\n",
    "    fold_pred = cb.predict(target) / 10\n",
    "    cb_pred += fold_pred\n",
    "print(f'10FOLD Mean of NMAE = {np.mean(cb_val)} & std = {np.std(cb_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "312903ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLD Training.....\n",
      "[22:57:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "1 FOLD NMAE = 0.09585665006796414\n",
      "\n",
      "2 FOLD Training.....\n",
      "[22:57:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "2 FOLD NMAE = 0.10365404597865192\n",
      "\n",
      "3 FOLD Training.....\n",
      "[22:57:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "3 FOLD NMAE = 0.10234304484097674\n",
      "\n",
      "4 FOLD Training.....\n",
      "[22:57:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "4 FOLD NMAE = 0.12797494362473733\n",
      "\n",
      "5 FOLD Training.....\n",
      "[22:57:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "5 FOLD NMAE = 0.09987375763044863\n",
      "\n",
      "6 FOLD Training.....\n",
      "[22:57:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "6 FOLD NMAE = 0.10629488261130283\n",
      "\n",
      "7 FOLD Training.....\n",
      "[22:57:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "7 FOLD NMAE = 0.08989357109792476\n",
      "\n",
      "8 FOLD Training.....\n",
      "[22:57:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "8 FOLD NMAE = 0.10246827516986926\n",
      "\n",
      "9 FOLD Training.....\n",
      "[22:57:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "9 FOLD NMAE = 0.10334358505141604\n",
      "\n",
      "10 FOLD Training.....\n",
      "[22:57:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "10 FOLD NMAE = 0.1060491478140011\n",
      "\n",
      "10FOLD Mean of NMAE = 0.10377519038872926 & std = 0.009336656938436043\n"
     ]
    }
   ],
   "source": [
    "# 초기화\n",
    "xgb_pred = np.zeros(target.shape[0])\n",
    "xgb_val = []\n",
    "\n",
    "for n, (tr_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    print(f'{n + 1} FOLD Training.....')\n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], np.expm1(y.iloc[val_idx])\n",
    "    \n",
    "    # xgb 학습\n",
    "    xgb = XGBRegressor(random_state = 42, criterion = 'mae')\n",
    "    xgb.fit(tr_x, tr_y)\n",
    "    \n",
    "    val_pred = np.expm1(xgb.predict(val_x))\n",
    "    val_nmae = NMAE(val_y, val_pred) # NMAE\n",
    "    xgb_val.append(val_nmae) # 초기화한 리스트에 NMAE를 삽입.\n",
    "    print(f'{n + 1} FOLD NMAE = {val_nmae}\\n')\n",
    "    \n",
    "    fold_pred = xgb.predict(target) / 10\n",
    "    xgb_pred += fold_pred\n",
    "\n",
    "print(f'10FOLD Mean of NMAE = {np.mean(xgb_val)} & std = {np.std(xgb_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed69cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FOLD Training.....\n",
      "[LightGBM] [Warning] Unknown parameter: criterion\n",
      "1 FOLD NMAE = 0.08965525753168317\n",
      "\n",
      "2 FOLD Training.....\n",
      "[LightGBM] [Warning] Unknown parameter: criterion\n",
      "2 FOLD NMAE = 0.09204765642380996\n",
      "\n",
      "3 FOLD Training.....\n",
      "[LightGBM] [Warning] Unknown parameter: criterion\n",
      "3 FOLD NMAE = 0.10725799296644017\n",
      "\n",
      "4 FOLD Training.....\n",
      "[LightGBM] [Warning] Unknown parameter: criterion\n",
      "4 FOLD NMAE = 0.12752712689735532\n",
      "\n",
      "5 FOLD Training.....\n",
      "[LightGBM] [Warning] Unknown parameter: criterion\n",
      "5 FOLD NMAE = 0.09191914851241564\n",
      "\n",
      "6 FOLD Training.....\n",
      "[LightGBM] [Warning] Unknown parameter: criterion\n",
      "6 FOLD NMAE = 0.09912622286935108\n",
      "\n",
      "7 FOLD Training.....\n",
      "[LightGBM] [Warning] Unknown parameter: criterion\n",
      "7 FOLD NMAE = 0.08867373084975455\n",
      "\n",
      "8 FOLD Training.....\n",
      "[LightGBM] [Warning] Unknown parameter: criterion\n",
      "8 FOLD NMAE = 0.0907089480909202\n",
      "\n",
      "9 FOLD Training.....\n",
      "[LightGBM] [Warning] Unknown parameter: criterion\n",
      "9 FOLD NMAE = 0.10531487169660025\n",
      "\n",
      "10 FOLD Training.....\n",
      "[LightGBM] [Warning] Unknown parameter: criterion\n",
      "10 FOLD NMAE = 0.10295641978149356\n",
      "\n",
      "10FOLD Mean of NMAE = 0.0995187375619824 & std = 0.01138428061682549\n"
     ]
    }
   ],
   "source": [
    "# 초기화\n",
    "lgbm_pred = np.zeros(target.shape[0])\n",
    "lgbm_val = []\n",
    "\n",
    "for n, (tr_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    print(f'{n + 1} FOLD Training.....')\n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], np.expm1(y.iloc[val_idx])\n",
    "    \n",
    "    # xgb 학습\n",
    "    lgbm = LGBMRegressor(random_state = 42, criterion = 'mae')\n",
    "    lgbm.fit(tr_x, tr_y)\n",
    "    \n",
    "    val_pred = np.expm1(lgbm.predict(val_x))\n",
    "    val_nmae = NMAE(val_y, val_pred) # NMAE\n",
    "    lgbm_val.append(val_nmae) # 초기화한 리스트에 NMAE를 삽입.\n",
    "    print(f'{n + 1} FOLD NMAE = {val_nmae}\\n')\n",
    "    \n",
    "    fold_pred = lgbm.predict(target) / 10\n",
    "    lgbm_pred += fold_pred\n",
    "\n",
    "print(f'10FOLD Mean of NMAE = {np.mean(lgbm_val)} & std = {np.std(lgbm_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5d6b283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09770088\n",
      "0.09769581\n",
      "0.12102229\n",
      "0.11641739\n",
      "0.09957309\n",
      "0.09879091\n",
      "0.09491902\n",
      "0.10810863\n",
      "0.10377519\n",
      "0.09951874\n"
     ]
    }
   ],
   "source": [
    "# 검증 성능 확인하기\n",
    "val_list = [lr_val, rg_val, ls_val, el_val, gbr_val, rf_val, ngb_val, cb_val, xgb_val, lgbm_val]\n",
    "for val in val_list :\n",
    "    print(\"{:.8f}\".format(np.mean(val))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b305192",
   "metadata": {},
   "source": [
    "0.09491902 + 0.09879091 + 0.09769581 + 0.09957309"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1be4af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8aefe813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       336185.372002\n",
       "1       126674.570725\n",
       "2       174364.865468\n",
       "3       238372.108291\n",
       "4       129522.161789\n",
       "            ...      \n",
       "1345    329908.652112\n",
       "1346    124872.015850\n",
       "1347     77339.468512\n",
       "1348    197182.081454\n",
       "1349    140603.137902\n",
       "Name: target, Length: 1350, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submission 파일에 입력\n",
    "sub = pd.read_csv(osp.join(data_dir, 'sample_submission.csv'))\n",
    "sub['target'] = np.expm1((ngb_pred + rf_pred + rg_pred + gbr_pred + lgbm_pred) / 5)\n",
    "sub['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82b168ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일로 내보내기\n",
    "sub.to_csv('./11th.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39163e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
